# jemdoc: menu{MENU}{index.html}, showsource, analytics{UA-31107207-1}
= Jiahui Cheng

~~~
{}{img_left}{./avatar/avatar.jpg}{Jiahui Cheng}{260px}{260px}
~~~
 \n
*Research Interests*: /Computational Math and Statistical Analysis, Generative Modeling.   /\n\n I have a broad interest in tackling challenging problems , [https://arxiv.org/abs/2108.08481 {{<font color=red size=+0.5><b>}}Neural Operator Learning{{</b></font>}}], [https://arxiv.org/abs/2007.02848 {{<font color=red size=+0.5><b>}}PDE Identification{{</b></font>}}], and [https://arxiv.org/abs/2303.01469 {{<font color=red size=+0.5><b>}}Diffusion Model Distillation{{</b></font>}}].

My previous interest lies high dimensional problem (e.g., [https://arxiv.org/abs/1903.08560 {{<font color=red size=+0.5><b>}}Double Descent phenomenon{{</b></font>}}]), image-to-image translation (e.g., [https://arxiv.org/abs/1611.07004 {{<font color=red size=+0.5><b>}}Pix2pix{{</b></font>}}], [https://arxiv.org/abs/1703.10593 {{<font color=red size=+0.5><b>}}Cycle GAN{{</b></font>}}]).\n
\n
I am currently a fourth-year graduate student at Georgia Tech, and I am very fortunate to be advised by [https://people.math.gatech.edu/~wliao60/ Wenjing Liao].   Prior to that, I received my bachelor's degree from [https://en.scgy.ustc.edu.cn/ School of Gifted Young] at University of Science and Technology of China (USTC). \n
\n
*Note*: Click on {{<font color=red size=+0.5><b>}}\[summary\]{{</b></font>}} or {{<font color=red size=+0.5><b>}}\[highlight\]{{</b></font>}} to view summaries or highlight of the papers/projects! \n
\n
== *Selected Publications*

=== PDE Identification
- *Ensemble Dynamics Guided Weak Formulation for Identifying Differential Equations.* \n
Jiahui Cheng, Sungha Kang, Haomin Zhou, Wenjing Liao.\n
Preprint, 2023 \n

=== Estimation Theory
- *Deep Neural Networks are Adaptive to Function Regularity and Data Distribution in Approximation and Estimation.* 
[https://arxiv.org/pdf/2406.05320 \[arxiv\]] {{<span class="title" onclick="toggle('summary-highdim')" style="cursor:pointer; u:hover">
<font color=red>
[Summary]
</font>
</span><br>
<span id="summary-highdim" style="display:none; border:1pt solid; padding: 5px; width:800px; background-color:lavender">
Deep learning has exhibited remarkable results across diverse areas. To understand its success, substantial research has been directed towards its theoretical foundations. Nevertheless, the majority of these studies examine how well deep neural networks can model functions with uniform regularity. In this paper, we explore a different angle: how deep neural networks can adapt to different regularity in functions across different locations and scales and nonuniform data distributions. More precisely, we focus on a broad class of functions defined by nonlinear treebased approximation. This class encompasses a range of function types, such as functions with uniform regularity and discontinuous functions. We develop nonparametric approximation and estimation theories for this function class using deep ReLU networks. Our results show that deep neural networks are adaptive to different regularity of functions and nonuniform data distributions at different locations and scales. We apply our results to several function classes, and derive the corresponding approximation and generalization errors. The validity of our results is demonstrated through numerical experiments.
</span>}}
Hao Liu, Jiahui Cheng, Wenjing Liao. \n
Preprint, 2024 \n

=== High Dimensional Statistics
- * High Dimensional Binary Classification under Label Shift: Phase Transition and Regularization.*
[https://arxiv.org/abs/2212.00700 \[arxiv\]] {{<span class="title" onclick="toggle('summary-highdim')" style="cursor:pointer; u:hover">
<font color=red>
[Summary]
</font>
</span><br>
<span id="summary-highdim" style="display:none; border:1pt solid; padding: 5px; width:800px; background-color:lavender">
Label Shift has been widely believed to be harmful to the generalization performance of machine learning models. Researchers have proposed many approaches to mitigate the impact of the label shift, e.g., balancing the training data. However, these methods often consider the underparametrized regime, where the sample size is much larger than the data dimension. The research under the overparametrized regime is very limited. To bridge this gap, we propose a new asymptotic analysis of the Fisher Linear Discriminant classifier for binary classification with label shift. Specifically, we prove that there exists a phase transition phenomenon: Under certain overparametrized regime, the classifier trained using imbalanced data outperforms the counterpart with reduced balanced data. Moreover, we investigate the impact of regularization to the label shift: The aforementioned phase transition vanishes as the regularization becomes strong.
</span>}}
Jiahui Cheng, Minshuo Chen, Hao Liu, Tuo Zhao, Wenjing Liao.\n
Sampling Theory, Signal Processing, and Data Analysis, 2022 \n

=== Inverse Problem
- *Estimate the spectrum of affine dynamical systems from partial observations of a single trajectory data* [https://arxiv.org/abs/2105.02945 \[arxiv\]] {{<span class="title" onclick="toggle('summary-estspec')" style="cursor:pointer; u:hover">
<font color=red>
[Summary]
</font>
</span><br>
<span id="summary-estspec" style="display:none; border:1pt solid; padding: 5px; width:800px; background-color:lavender">
In this paper, we study the nonlinear inverse problem of estimating the spectrum of a system matrix, that drives a 
finite-dimensional affine dynamical system, from partial observations of a single trajectory data. In the noiseless case, we prove an 
annihilating polynomial of the system matrix, whose roots are a subset of the spectrum, can be uniquely determined from data. We then 
study which eigenvalues of the system matrix can be recovered and derive various sufficient and necessary conditions to characterize the
relationship between the recoverability of each eigenvalue and the observation locations. We propose various reconstruction algorithms,
with theoretical guarantees, generalizing the classical Prony method, ESPIRIT, and matrix pencil method. We test the algorithms over a 
variety of examples with applications to graph signal processing, disease modeling and a real-human motion dataset. The numerical 
results validate our theoretical results and demonstrate the effectiveness of the proposed algorithms, even when the data did not follow 
an exact linear dynamical system.
</span>}}
Jiahui Cheng, Sui Tang\n
Inverse Problem, 2021 \n

=== Solids and Fluids Simulation
- *Continuum simulation based on Material Point Method* {{<span class="title" onclick="toggle('summary-contsim')" style="cursor:pointer; u:hover">
<font color=red>
[Summary]
</font>
</span><br>
<span id="summary-contsim" style="display:none; border:1pt solid; padding: 5px; width:800px; background-color:lavender">
In this thesis, we study the hybrid Eulerian/ Lagrangian Material Point Method (MPM) and propose a new discretization for the weak form 
of MPM based on the weak form of force balance and alleviated the energy dissipation. We improve the stability and energy dissipation 
compared with MPM and Affine Particle in Cell method. We implemented a Java Graphical User Interface (GUI) for visualization of our 
algorithm for snow simulation. 
</span>}}
Jiahui Cheng, Weihua Tong\n
Bachelor's thesis, 2020 \n

== [papersYear.html *Full Publications*]\n